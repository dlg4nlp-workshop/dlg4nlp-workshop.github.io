<!DOCTYPE HTML>

<html>
	<head>
		<title>Welcome to DLG4NLP@ICLR’22!</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header">
					<!-- Logo -->
<!--						<img src="images/isail_logo.png" alt="" /><span><h2>Welcome to <a href="index.html" id="logo">iSAIL</a> Lab !</h2></span>-->

					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="index.html">Home</a></li>
								<li><a href="cfp.html">CFP</a></li>
								<li><a href="schedule.html">Schedule</a></li>
								<li class="current"><a href="keynote.html">Keynote</a></li>
								<li><a href="publications.html">Accepted Papers</a></li>
								<li><a href="organization.html">Organization</a></li>
								<li><a href="history.html">History</a></li>
							</ul>
						</nav>

				</div>
			<!-- Banner -->
				<section id="banner">
					<header>
						<h2>Welcome to Deep Learning on Graphs for Natural Language Processing (DLG4NLP@ICLR’22)!</h2>
						<!--<a href="#" class="button">Learn More</a>-->
					</header>
				</section>
                <section class="wrapper style1">

					<!-- <div class="container">
						<div id="content">
							<h2 class="section-heading">TBD</h2>

						</div>
					</div> -->
					
					<!-- <div style="overflow: hidden;">
					   <div id="A" style="float:left; width: 20%;">
						  <img src="images/hanj_tour.jpeg" alt="" width="180px" style="margin:0px 50px">
					   </div>
					   <div id="B" style="float: left; width: 75%;">
						  <div>
							<b>Jiawei Han</b> is Abel Bliss professor in the Department of Computer Science, University of Illinois. He has been researching data mining, information network analysis, and database systems, with more than 600 publications. He served as the founding editor-in-chief of the ACM Transactions on Knowledge Discovery from Data (TKDD). He has received the ACM SIGKDD Innovation Award (2004), IEEE Computer Society Technical Achievement Award (2005), IEEE Computer Society W. Wallace McDowell Award (2009), and Daniel C. Drucker Eminent Faculty Award at UIUC (2011). He is currently the director of the Information Network Academic Research Center (INARC) supported by the Network Science-Collaborative Technology Alliance (NS-CTA) program of the U.S. Army Research Lab. His co-authored textbook Data Mining: Concepts and Techniques (Morgan Kaufmann) has been adopted worldwide. He is a fellow of the IEEE and ACM.
						  </div>
						   <div>
							<b>Title: </b>TBA.
						  </div>
						   <div>
							<b>Abstract: </b>TBA.
							<hr />
						  </div>
						  	
					   </div>
					</div>
                    
                    <div style="overflow: hidden;">
                        <div id="A" style="float:left; width: 20%;">
                            <img src="images/hengji.png" alt="" width="180px" style="margin:0px 50px">
                                </div>
                        <div id="B" style="float: left; width: 75%;">
                            <div>
                                <b>Heng Ji</b> is a professor at the Computer Science Department of University of Illinois at Urbana-Champaign. She has received many awards including "AI's 10 to Watch" Award by IEEE Intelligent Systems in 2013, NSF CAREER award in 2009, PACLIC2012 Best paper runner-up, "Best of ICDM2013" paper award, and "Best of SDM2013" paper award. She has served as the Program Committee Co-Chair of NAACL-HLT2018, NLP-NABD2018, NLPCC2015, CSCKG2016 and CCL2019, and senior area chair for many conferences.
                            </div>
                            <div>
                                <b>Title: </b>TBA.
                            </div>
                            <div>
                                <b>Abstract: </b>TBA.
                                <hr />
                            </div>
                            
                        </div>
                    </div> -->
                    
                    <div style="overflow: hidden;">
                        <div id="A" style="float:left; width: 20%;">
                            <img src="images/ititov.jpg" alt="" width="180px" style="margin:0px 50px">
                                </div>
                        <div id="B" style="float: left; width: 75%;">
                            <div>
                                <a href="http://ivan-titov.org" target = "_blank"><b>Ivan Titov</b></a> is an associate professor in the Institute for Language, Cognition and Computation (ILCC) at the School of Informatics of the University of Edinburgh. He is an action editor for the journal of machine learning research (JMLR), Transactions of ACL (TACL), a member of editorial board of JAIR, an advisory board member for European Chapter of ACL. His other professional services include being a PC co-chair for *SEM 2016 and CoNLL 2018, a senior area chair for ACL 2019 and a program co-chair for ICLR 2021.
                            </div>
                            <div>
                                <b>Title: </b>TBA.
                            </div>
                            <div>
                                <b>Abstract: </b>TBA.
                                <hr />
                            </div>
                            
                        </div>
                    </div>

					<div style="overflow: hidden;">
                        <div id="A" style="float:left; width: 20%;">
                            <img src="images/xpqiu.jpg" alt="" width="180px" style="margin:0px 50px">
                                </div>
                        <div id="B" style="float: left; width: 75%;">
                            <div>
                                <a href="https://xpqiu.github.io/en.html" target = "_blank"><b>Xipeng Qiu</b></a> is a professor at the School of Computer Science, Fudan University. He received his B.S. and Ph.D. degrees from Fudan University. His research interests include natural language processing and deep learning. He has published more than 60 top journal/conference papers (e.g., TACL, TKDE, T-ALS, ACL, EMNLP, IJCAI, AAAI, ICCV). He also leads the development of FudanNLP and fastNLP.
                            </div>
                            <div>
                                <b>Title: </b>TBA.
                            </div>
                            <div>
                                <b>Abstract: </b>TBA.
                                <hr />
                            </div>
                            
                        </div>
                    </div>

					<div style="overflow: hidden;">
                        <div id="A" style="float:left; width: 20%;">
                            <img src="images/perlmutter.jpg" alt="" width="180px" style="margin:0px 50px">
                                </div>
                        <div id="B" style="float: left; width: 75%;">
                            <div>
                                <a href="https://sites.google.com/view/perlmutma/home" target = "_blank"><b>Michael Perlmutter</b></a> is a Hedrick Assistant Adjunct Professor in the Department of Mathematics at UCLA working under the supervision of Deanna Needell. His current research is focused on  the mathematics of data science including applied harmonic analysis and probability.
                            </div>
                            <div>
                                <b>Title: </b>Geometric Scattering: Graph Neural Nets that Preserve High-Frequency Information
                            </div>
                            <div>
                                <b>Abstract: </b> Many advances in deep learning exploit the intrinsic structure of the data. For instance, Convolutional Neural Networks leverage the fact that images are a regular grid of pixels, whereas recurrent neural networks exploit the temporal structure of text-based data. Inspired by this success, the new field of geometric deep learning aims to develop deep learning architectures for datasets such as graphs and manifolds with less regular structure. 
								<br />
								A principal challenge in this endeavor is defining a proper notion of convolutional filters. Many graph neural networks propose to define graph convolution as a localized averaging operation. While these networks achieve great success on benchmark datasets, they are known to suffer from the oversmoothing problem, i.e., they do not preserve high-frequency information. This motivates us to define an alternative, wavelet-based model of graph neural networks known as the graph scattering transform. In its initial form, the graph scattering transform is a handcrafted network with no learnable parameters (except in the final layer). This version of the graph scattering transform has the advantage of (i) being amenable to rigorous mathematical analysis and (ii) not requiring much training data. However, handcraftedness is also a form of rigidity that limits the ability of the network to learn. Therefore, I will also introduce several new variations of the graph scattering transform which are able to learn from data.
                                <hr />
                            </div>
                            
                        </div>
                    </div>

					<div style="overflow: hidden;">
                        <div id="A" style="float:left; width: 20%;">
                            <img src="images/Diyi_Yang.jpg" alt="" width="180px" style="margin:0px 50px">
                                </div>
                        <div id="B" style="float: left; width: 75%;">
                            <div>
								<a href="https://faculty.cc.gatech.edu/~dyang888/" target = "_blank"><b>Diyi Yang</b></a> is an assistant professor in the School of Interactive Computing at Georgia Tech. She is broadly interested in Computational Social Science, and Natural Language Processing. Diyi received her PhD from the Language Technologies Institute at Carnegie Mellon University. Her work has been published at leading NLP/HCI conferences, and also resulted in multiple award nominations from EMNLP, ICWSM, SIGCHI and CSCW. She is named as a Forbes 30 under 30 in Science, a recipient of IEEE AI 10 to Watch, and has received faculty research awards from Amazon, Facebook, JPMorgan Chase, and Salesforce.
                            </div>
                            <div>
                                <b>Title: </b>A Closer Look at Structure and Sparsity in Graph Based Natural Language Understanding
                            </div>
                            <div>
                                <b>Abstract: </b>Graph based approaches have been increasingly utilized for different NLP applications, however, what types of structures should be leveraged and to what extent these graph structures help still remain challenging. In this talk, we take a closer look at graph neural networks via two typical NLP applications: structure-aware conversation summarization and knowledge-graph enhanced question answering. Concretely, the first section looks at how to utilize graph structures to better encode discourse relations and actions in conversations for improved dialogue summarization, and the second part  dissects state-of-the-art graph neural network modules and their reasoning capability for question answering.
                                <hr />
                            </div>
                            
                        </div>
                    </div>
					
                    
                    <!-- <div style="overflow: hidden;">
                        <div id="A" style="float:left; width: 20%;">
                            <img src="images/regina.png" alt="" width="180px" style="margin:0px 50px">
                                </div>
                        <div id="B" style="float: left; width: 75%;">
                            <div>
                                <b>Regina Barzilay</b> is a professor at the Massachusetts Institute of Technology and a member of MIT Computer Science and Artificial Intelligence Laboratory. Her research interests are in natural language processing and applications of deep learning to chemistry and oncology. She received a MacArthur fellowship, an ACL fellowship and an AAAI fellowship.
                            </div>
                            <div>
                                <b>Title: </b>TBA.
                            </div>
                            <div>
                                <b>Abstract: </b>TBA.
                                <hr />
                            </div>
                            
                        </div>
                    </div>
					
					<div style="overflow: hidden;">
					   <div id="A" style="float:left; width: 20%;">
						  <img src="images/McCallumAndrew.jpg" alt="" width="180px" style="margin:0px 50px">
					   </div>
					   <div id="B" style="float: left; width: 75%;">
						  <div>
							<b>Andrew McCallum</b> is a Distinguished Professor and Director of the Center for Data Science in the College of Information and Computer Sciences at the University of Massachusetts Amherst. He was the Program Co-chair for the International Conference on Machine Learning (ICML) 2008, its General Chair in 2012, and from 2013 to 2017 was the President of the International Machine Learning Society.
						  </div>
						   <div>
							<b>Title: </b>TBA.
						  </div>
						   <div>
							<b>Abstract: </b>TBA.
							<hr />
						  </div>
						  	
					   </div>
					</div>

					<div style="overflow: hidden;">
						<div id="A" style="float:left; width: 20%;">
						   <img src="images/alexgray.jpg" alt="" width="180px" style="margin:0px 50px">
						</div>
						<div id="B" style="float: left; width: 75%;">
						   <div>
							<b>Alexander Gray</b> serves as VP of Foundations of AI at IBM, leading IBM’s basic AI research globally. He previously served as CEO and CTO of Skytree, which he co-founded, then at Infosys as GM of Research and Fellow. Prior to that, he served as a tenured Associate Professor at the Georgia Institute of Technology. His work helped enable the Science journal’s Top Breakthrough of 2003, and have won a number of research awards. He served as a member of the 2010 National Academy of Sciences Committee on the Analysis of Massive Data, a National Academy of Sciences Kavli Scholar, and a frequent advisor and speaker on topics of large-scale machine learning and data science at top research conferences, government agencies, and leading corporations.
						</div>
							<div>
							 <b>Title: </b>TBA.
						   </div>
							<div>
							 <b>Abstract: </b>TBA.
							 <hr />
						   </div>
							   
						</div>
					 </div> -->

				</section>


	
			<!-- Footer -->
				<div id="footer">
					<div class="container">

						<div class="row">

							<section class="col-6 col-12-narrower">
								<h3>Get In Touch</h3>
								<table style="width: 90%">
									<tbody>
										<tr class="trow">
											<td><i class="fa fa-envelope" style="font-size: 20px;"></i> <a href="mailto:dlg4nlp.workshop@gmail.com">dlg4nlp.workshop@gmail.com</a></td>
										</tr>
										<!-- <tr class="trow">
											<td><i class="fa fa-envelope" style="font-size: 20px;"></i> <a href="mailto:second@mail">second@mail</a></td> -->
										</tr>
									</tbody>
								</table>
							</section>
						</div>
					</div>

					<!-- Icons -->
						<!-- <ul class="icons">
							<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
							<li><a href="#" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
							<li><a href="#" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
							<li><a href="#" class="icon brands fa-google-plus-g"><span class="label">Google+</span></a></li>
						</ul> -->

					<!-- Copyright -->
						<div class="copyright">
							<ul class="menu">
								<li>&copy; DLG4NLP. All rights reserved</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>

				</div>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
